from typing import List, Dict, Any, Optional
from motor.motor_asyncio import AsyncIOMotorCollection
from datetime import datetime
import uuid
import logging

from .search_service import web_search_service
from .llm_service import ghassan_llm_service
from .claude_service import claude_direct_service
from .tavily_service import tavily_search_service
from data.omani_knowledge_base import OMANI_LITERATURE_KNOWLEDGE_BASE, EXTRACTED_KNOWLEDGE
from data.omani_curriculum import OMANI_ARABIC_CURRICULUM

logger = logging.getLogger(__name__)

class ChatService:
    def __init__(self, db):
        self.db = db
        self.messages_collection: AsyncIOMotorCollection = db.messages
        self.sessions_collection: AsyncIOMotorCollection = db.sessions
    
    async def process_user_message(
        self,
        message_text: str,
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ ØªØ°ÙƒØ± Ø§Ù„Ø³ÙŠØ§Ù‚"""
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ session_id Ø¬Ø¯ÙŠØ¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            if not session_id:
                session_id = await self._create_new_session()
            
            # **Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ø³ÙŠØ§Ù‚**
            recent_messages = await self.get_chat_history(session_id, limit=5)
            conversation_context = self._build_conversation_context(recent_messages)
            
            # Ø­ÙØ¸ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            user_message = await self._save_message(
                text=message_text,
                sender='user',
                session_id=session_id
            )
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªØ§Ø¬ Ø¨Ø­Ø«
            needs_search = self._message_needs_search(message_text)
            search_results = []
            
            # **ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨**
            student_level = self._detect_student_level(message_text, conversation_context)
            curriculum_context = self._get_curriculum_context(message_text, student_level)
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
            local_knowledge = self._search_local_knowledge_base(message_text)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªØ§Ø¬ Ø¨Ø­Ø« Ø®Ø§Ø±Ø¬ÙŠ
            if needs_search and not local_knowledge:
                logger.info(f"Ø±Ø³Ø§Ù„Ø© ØªØ­ØªØ§Ø¬ Ø¨Ø­Ø« Ù…ØªÙ‚Ø¯Ù… Ø¨Ù€ Tavily: {message_text}")
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Tavily Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
                tavily_results = await tavily_search_service.search_omani_literature_advanced(message_text)
                
                # ØªØ­ÙˆÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Tavily Ù„ØµÙŠØºØ© Ù…ÙˆØ­Ø¯Ø©
                search_results = self._convert_tavily_to_standard_format(tavily_results)
            else:
                search_results = []
                if local_knowledge:
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„ØµÙŠØºØ© search_results
                    search_results = [{
                        'title': f"Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {local_knowledge['source']}",
                        'content': local_knowledge['content'],
                        'source': 'Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©',
                        'reliability_score': local_knowledge.get('reliability', 0.95)
                    }]
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø¨ÙŠ Ù…ØªÙ‚Ø¯Ù…
            needs_advanced_analysis = self._needs_advanced_literary_analysis(message_text)
            use_claude = self._should_use_claude_analysis(message_text)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ ØºØ³Ø§Ù† Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ
            logger.info(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ: {message_text[:50]}...")
            llm_response = await ghassan_llm_service.generate_response_with_search(
                message_text, 
                search_results=search_results,
                session_id=session_id,
                use_claude=use_claude,
                conversation_context=conversation_context,
                curriculum_context=curriculum_context  # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ
            )
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ ÙŠØ­ØªØ§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬ÙŠØ© Ø¨Ø¯ÙŠÙ„Ø©
            needs_external_links = self._needs_external_links_fallback(llm_response['text'], message_text)
            
            if needs_external_links:
                logger.info(f"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬ÙŠØ© Ø¨Ø¯ÙŠÙ„Ø©: {message_text}")
                external_links = await self._generate_external_links(message_text)
                if external_links:
                    llm_response['text'] += "\n\n" + external_links
                    llm_response['has_external_links'] = True
            
            # Ø­ÙØ¸ Ø±Ø¯ ØºØ³Ø§Ù†
            ghassan_message = await self._save_message(
                text=llm_response['text'],
                sender='ghassan',
                session_id=session_id,
                metadata={
                    'model_used': llm_response.get('model_used'),
                    'has_web_search': needs_search,
                    'search_results_count': len(search_results),
                    'has_external_links': llm_response.get('has_external_links', False)
                }
            )
            
            # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
            await self._update_session(session_id, llm_response['text'])
            
            return {
                'message_id': str(ghassan_message['_id']),
                'text': llm_response['text'],
                'session_id': session_id,
                'timestamp': ghassan_message['timestamp'],
                'has_web_search': needs_search,
                'model_used': llm_response.get('model_used', 'unknown')
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}")
            # Ø±Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
            return {
                'message_id': str(uuid.uuid4()),
                'text': 'Ø¹Ø°Ø±Ø§Ù‹ØŒ ÙˆØ§Ø¬Ù‡Øª Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ©. Ø£Ø±Ø¬Ùˆ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.',
                'session_id': session_id or str(uuid.uuid4()),
                'timestamp': datetime.utcnow(),
                'has_web_search': False,
                'model_used': 'error',
                'error': str(e)
            }
    
    async def get_chat_history(self, session_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """Ø¬Ù„Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ù„Ø¬Ù„Ø³Ø© Ù…Ø¹ÙŠÙ†Ø©"""
        try:
            messages = await self.messages_collection.find(
                {'session_id': session_id}
            ).sort('timestamp', 1).limit(limit).to_list(limit)
            
            return [self._format_message(msg) for msg in messages]
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª: {e}")
            return []
    
    async def _create_new_session(self) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
        session_id = str(uuid.uuid4())
        session_data = {
            '_id': session_id,
            'created_at': datetime.utcnow(),
            'updated_at': datetime.utcnow(),
            'message_count': 0,
            'title': 'Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ ØºØ³Ø§Ù†'
        }
        
        await self.sessions_collection.insert_one(session_data)
        return session_id
    
    async def _save_message(
        self,
        text: str,
        sender: str,
        session_id: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Ø­ÙØ¸ Ø±Ø³Ø§Ù„Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        message_data = {
            '_id': str(uuid.uuid4()),
            'text': text,
            'sender': sender,
            'session_id': session_id,
            'timestamp': datetime.utcnow(),
            'metadata': metadata or {}
        }
        
        await self.messages_collection.insert_one(message_data)
        return message_data
    
    async def _update_session(self, session_id: str, last_message: str):
        """ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©"""
        await self.sessions_collection.update_one(
            {'_id': session_id},
            {
                '$set': {
                    'updated_at': datetime.utcnow(),
                    'last_message': last_message[:100] + '...' if len(last_message) > 100 else last_message
                },
                '$inc': {'message_count': 1}
            }
        )
    
    def _message_needs_search(self, message: str) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªØ­ØªØ§Ø¬ Ø¨Ø­Ø« Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª"""
        search_indicators = [
            'Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¹Ù†', 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù†', 'Ù…Ù† Ù‡Ùˆ', 'Ù…Ù† Ù‡ÙŠ', 'Ù…Ø§ Ù‡Ùˆ', 'Ù…Ø§ Ù‡ÙŠ',
            'Ø¨Ø­Ø«', 'Ø§Ø¨Ø­Ø«', 'Ø§Ø¹Ø«Ø± Ø¹Ù„Ù‰', 'Ø£Ø±ÙŠØ¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'Ù‡Ù„ ØªØ¹Ø±Ù',
            'ØªÙØ§ØµÙŠÙ„', 'Ø®Ù„ÙÙŠØ©', 'Ø³ÙŠØ±Ø©', 'ØªØ§Ø±ÙŠØ®', 'Ù†Ø´Ø£Ø©', 'ÙˆÙ„Ø§Ø¯Ø©',
            'Ø£Ø¹Ù…Ø§Ù„', 'ÙƒØªØ¨', 'Ù‚ØµØ§Ø¦Ø¯', 'Ø±ÙˆØ§ÙŠØ§Øª', 'Ù…Ø¤Ù„ÙØ§Øª'
        ]
        
        message_lower = message.lower()
        return any(indicator in message_lower for indicator in search_indicators)
    
    def _needs_advanced_literary_analysis(self, message: str) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªØ­ØªØ§Ø¬ ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø¨ÙŠ Ù…ØªÙ‚Ø¯Ù…"""
        advanced_keywords = [
            'ØªØ­Ù„ÙŠÙ„', 'Ù†Ù‚Ø¯', 'Ø¥Ø¹Ø±Ø§Ø¨', 'Ø¨Ù„Ø§ØºØ©', 'Ø¹Ø±ÙˆØ¶', 'Ø¨Ø­Ø± Ø´Ø¹Ø±ÙŠ', 
            'Ù‚Ø§ÙÙŠØ©', 'Ø§Ø³ØªØ¹Ø§Ø±Ø©', 'ÙƒÙ†Ø§ÙŠØ©', 'Ù…Ø¬Ø§Ø²', 'ØªØ´Ø¨ÙŠÙ‡',
            'Ø¨Ù†ÙŠØ©', 'Ø£Ø³Ù„ÙˆØ¨', 'Ù†Ø¸Ø±ÙŠØ©', 'Ù…Ù†Ù‡Ø¬', 'Ù…Ø¯Ø±Ø³Ø© Ø£Ø¯Ø¨ÙŠØ©',
            'Ù†Ø­Ùˆ', 'ØµØ±Ù', 'Ø¨Ø¯ÙŠØ¹', 'Ø¨ÙŠØ§Ù†', 'Ù…Ø¹Ø§Ù†ÙŠ'
        ]
        
        return any(keyword in message.lower() for keyword in advanced_keywords)
    
    def _should_use_claude_analysis(self, message: str) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ù…ØªÙ‰ Ù†Ø³ØªØ®Ø¯Ù… Claude Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
        # Ø§Ø³ØªØ®Ø¯Ù… Claude Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø¨ÙŠØŒ Ø§Ù„Ù†Ø­ÙˆÙŠØŒ ÙˆØ§Ù„Ø¨Ù„Ø§ØºÙŠ
        claude_specific = [
            'ØªØ­Ù„ÙŠÙ„', 'Ù†Ù‚Ø¯', 'Ø¥Ø¹Ø±Ø§Ø¨', 'Ø¨Ù„Ø§ØºØ©', 'Ø¹Ø±ÙˆØ¶',
            'Ù†Ø­Ùˆ', 'ØµØ±Ù', 'Ø´Ø§Ø¹Ø±ÙŠØ©', 'Ø£Ø³Ù„ÙˆØ¨', 'Ø¨Ù†ÙŠØ©',
            'Ù†Ø¸Ø±ÙŠØ©', 'Ù…Ù†Ù‡Ø¬', 'Ø¯Ø±Ø§Ø³Ø© Ø£Ø¯Ø¨ÙŠØ©'
        ]
        
        return any(keyword in message.lower() for keyword in claude_specific)
    
    def _format_search_context(self, search_results: List[Dict[str, Any]]) -> str:
        """ØªÙ†Ø³ÙŠÙ‚ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ù„Ù€ Claude"""
        if not search_results:
            return ""
        
        context = "--- Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø© ---\n"
        for result in search_results:
            context += f"â€¢ {result.get('title', 'N/A')}\n"
            context += f"Ø§Ù„Ù…ØµØ¯Ø±: {result.get('source', 'N/A')}\n"
            context += f"Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {result.get('content', '')[:200]}...\n\n"
        
        return context
    
    def _convert_tavily_to_standard_format(self, tavily_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ØªØ­ÙˆÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Tavily Ø¥Ù„Ù‰ Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
        if not tavily_results.get('results'):
            return []
        
        standard_results = []
        for result in tavily_results['results']:
            standard_result = {
                'title': result.get('title', ''),
                'content': result.get('content', ''),
                'url': result.get('url', ''),
                'source': f"Tavily - {result.get('source_type', 'Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚')}",
                'reliability_score': result.get('reliability_rating', 0.8),
                'search_engine': 'tavily_advanced',
                'omani_keywords': result.get('omani_keywords', [])
            }
            standard_results.append(standard_result)
        
        return standard_results
    
    def _build_conversation_context(self, recent_messages: List[Dict[str, Any]]) -> str:
        """Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        if not recent_messages:
            return ""
        
        context = "--- Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ---\n"
        
        for msg in recent_messages[-4:]:  # Ø¢Ø®Ø± 4 Ø±Ø³Ø§Ø¦Ù„ ÙÙ‚Ø·
            sender = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…" if msg['sender'] == 'user' else "ØºØ³Ø§Ù†"
            context += f"{sender}: {msg['text'][:100]}...\n"
        
        context += "--- Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø³ÙŠØ§Ù‚ ---\n"
        context += "**ØªØ°ÙƒØ±:** Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ±Ø¨Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù…Ø§ Ø³Ø¨Ù‚.\n"
        
        return context
    
    def _search_local_knowledge_base(self, query: str) -> Optional[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©"""
        query_lower = query.lower()
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©
        for figure in EXTRACTED_KNOWLEDGE['omani_literary_figures']:
            if figure.lower() in query_lower:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                for category in OMANI_LITERATURE_KNOWLEDGE_BASE.values():
                    if isinstance(category, dict):
                        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡
                        if 'poets' in category:
                            for poet in category['poets']:
                                if poet['name'] == figure:
                                    return {
                                        'content': f"Ø§Ù„Ø´Ø§Ø¹Ø± {poet['name']} Ù…Ù† {poet.get('period', 'Ø§Ù„Ø¹ØµØ± Ø§Ù„Ù‚Ø¯ÙŠÙ…')}ØŒ {poet.get('significance', '')}. {poet.get('notes', '')}",
                                        'source': 'Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© ÙÙŠ Ø¹ÙÙ…Ø§Ù† - Ø§Ù„Ø¬Ù‡Ø¶Ù…ÙŠ',
                                        'reliability': 0.95,
                                        'type': 'poet'
                                    }
                        
                        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒØªØ§Ø¨ Ø§Ù„Ù†Ø«Ø±
                        if 'writers' in category:
                            for writer in category['writers']:
                                if writer['name'] == figure:
                                    return {
                                        'content': f"{writer['name']} {writer.get('type', '')} Ù…Ù† {writer.get('family', '')}. {writer.get('significance', '')}. Ù…Ù† Ø£Ø¹Ù…Ø§Ù„Ù‡: {writer.get('famous_work', '')}.",
                                        'source': 'Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© ÙÙŠ Ø¹ÙÙ…Ø§Ù† - Ø§Ù„Ø¬Ù‡Ø¶Ù…ÙŠ',
                                        'reliability': 0.95,
                                        'type': 'prose_writer'
                                    }
                        
                        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¹Ù„Ù…Ø§Ø¡
                        if 'scholars' in category:
                            for scholar in category['scholars']:
                                if scholar['name'] == figure:
                                    return {
                                        'content': f"{scholar['name']} {scholar.get('title', '')}. Ù…Ù† Ø£Ø¹Ù…Ø§Ù„Ù‡: {scholar.get('works', '')}. {scholar.get('significance', '')}.",
                                        'source': 'Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© ÙÙŠ Ø¹ÙÙ…Ø§Ù† - Ø§Ù„Ø¬Ù‡Ø¶Ù…ÙŠ',
                                        'reliability': 0.95,
                                        'type': 'scholar'
                                    }
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        for concept in EXTRACTED_KNOWLEDGE['key_concepts']:
            if any(word in query_lower for word in concept.lower().split()):
                return {
                    'content': f"Ù…Ù† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ø£Ø¯Ø¨ Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {concept}. ÙˆÙÙ‚Ø§Ù‹ Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¬Ù‡Ø¶Ù…ÙŠ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ø­ÙˆÙ„ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© ÙÙŠ Ø¹ÙÙ…Ø§Ù† Ø­ØªÙ‰ 134Ù‡Ù€.",
                    'source': 'Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©',
                    'reliability': 0.9,
                    'type': 'concept'
                }
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©
        for work in EXTRACTED_KNOWLEDGE['literary_works']:
            if any(word in work.lower() for word in query_lower.split() if len(word) > 3):
                return {
                    'content': f"Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {work}. Ù…Ø°ÙƒÙˆØ± ÙÙŠ Ø§Ù„Ø¯Ø±Ø§Ø³Ø§Øª Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ø­ÙˆÙ„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£Ø¯Ø¨ Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠ.",
                    'source': 'Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© Ø§Ù„Ø¹ÙÙ…Ø§Ù†ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©',
                    'reliability': 0.9,
                    'type': 'literary_work'
                }
        
        return None
    
    def _needs_external_links_fallback(self, response: str, query: str) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ ÙŠØ­ØªØ§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬ÙŠØ© Ø¨Ø¯ÙŠÙ„Ø©"""
        
        # Ø¹Ø¨Ø§Ø±Ø§Øª ØªØ¯Ù„ Ø¹Ù„Ù‰ Ø¹Ø¯Ù… ØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©
        fallback_indicators = [
            "Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
            "Ù„Ø§ Ø£Ø¹Ø±Ù",
            "ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©",
            "Ø£Ø­ØªØ§Ø¬ Ù„Ù„ØªØ­Ù‚Ù‚",
            "Ù…Ù† Ø§Ù„Ù…ÙÙŠØ¯ Ø§Ù„Ø¨Ø­Ø«",
            "Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©",
            "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø©"
        ]
        
        response_lower = response.lower()
        has_insufficient_info = any(indicator in response_lower for indicator in fallback_indicators)
        
        # Ø£ÙŠØ¶Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† 100 Ø­Ø±Ù)
        is_too_short = len(response.strip()) < 100
        
        return has_insufficient_info or is_too_short
    
    async def _generate_external_links(self, query: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬ÙŠØ© Ù…ÙÙŠØ¯Ø© Ø¹Ù†Ø¯ Ø¹Ø¯Ù… ØªÙˆÙØ± Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©"""
        
        try:
            # ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©
            enhanced_query = f"{query} site:nizwa.om OR site:omandaily.om OR site:moe.gov.om OR site:heritage.gov.om OR site:squ.edu.om"
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tavily
            search_results = await tavily_search_service.search_omani_literature_advanced(
                enhanced_query, 
                max_results=6
            )
            
            if not search_results.get('results'):
                return ""
            
            # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
            links_text = "\n\nğŸ“š **Ù„Ù… ØªØªÙˆÙØ± Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ Ù„ÙƒÙ† Ø¥Ù„ÙŠÙƒ Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø© Ø°Ø§Øª ØµÙ„Ø©:**\n\n"
            
            for i, result in enumerate(search_results['results'][:5], 1):
                title = result.get('title', 'Ù…ØµØ¯Ø± Ù…ÙÙŠØ¯')
                url = result.get('url', '')
                source_type = result.get('source_type', 'Ù…ØµØ¯Ø±')
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØªÙ‚ØµÙŠØ±Ù‡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
                if len(title) > 60:
                    title = title[:57] + "..."
                
                # Ø¥Ø¶Ø§ÙØ© Ø±Ù…Ø² Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø±
                icon = "ğŸ“–" if "academic" in source_type else "ğŸ“°" if "news" in source_type else "ğŸ”—"
                
                links_text += f"â€¢ {icon} **{title}**\n"
                links_text += f"  {url}\n\n"
            
            links_text += "ğŸ’¡ **Ù†ØµÙŠØ­Ø©**: Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙØµÙ„Ø© Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©."
            
            return links_text
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©: {e}")
            return ""
    
    def _format_message(self, msg: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ø¹Ù…ÙŠÙ„"""
        return {
            'id': msg['_id'],
            'text': msg['text'],
            'sender': msg['sender'],
            'timestamp': msg['timestamp'].isoformat(),
            'hasWebSearch': msg.get('metadata', {}).get('has_web_search', False),
            'modelUsed': msg.get('metadata', {}).get('model_used')
        }